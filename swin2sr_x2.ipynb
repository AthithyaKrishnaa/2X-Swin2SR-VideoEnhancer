{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uj7BEVtjAws"
   },
   "source": [
    "# Step 1: Install Dependencies\n",
    "We need to install the `transformers` library to use the Swin2SR model and `accelerate` for optimized performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1AwtojXjAww",
    "outputId": "51890bb8-9f5a-46fd-b3a4-fd3934257662"
   },
   "outputs": [],
   "source": [
    "!pip install transformers accelerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bphhMbSjAwy"
   },
   "source": [
    "# Step 2: Import Libraries and Load Model\n",
    "Here we load the Swin2SR processor and the lightweight X2 model from Hugging Face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 259,
     "referenced_widgets": [
      "d5aef38b6cbc4e93affc4df4f8208ad3",
      "7604903e20034291b0d7ed4de51bd3d4",
      "8b952f58ad8f48af8c3e0216b26d7a0b",
      "8dddb6901cf14139b1d82aedcb7658de",
      "0c1afd73385741af8229e8b43598f712",
      "680eea1c276d42349613d64842e10602",
      "94611ad711054ca0b4a73ad71dcfeb88",
      "f040686b8b7c4df1a2c961a4b4b1c5c9",
      "341fbd03589644ad9f6814635f8651b1",
      "ca5ebe82585a4c5a926aa4a366215313",
      "f3fdc17f99884b38b091332cd3a8f7f6",
      "021132d39bdb4befa33bab53ca0bbb9a",
      "cc2c16835cbf43ab9e5ee424ebf78848",
      "d0817d821cc3457b85b7a2b6e02783b8",
      "7ac0f4664122470d9d3cc559eac4e786",
      "4b37411843ab42d1bb8b3de9c63647f0",
      "07904e3edd1146f7ab1fc911bab36387",
      "9838415097944c6eab445ac16e80d1e4",
      "c4c1e28e8ccc49c89d44dc199112580a",
      "e7caa93ecff24f1b8f621e4fba15f829",
      "ed0adb6d951c4b7f9a33e2f0bbcb692f",
      "d3fd88278b2d427698af65df646d1397",
      "1c4323ba0aa94d42a3381fd40e1b6536",
      "93b58df39c274894b7bb8adc0babf21b",
      "5b844e9bd2a243409abfa0490eb9b0ae",
      "625e6d53914a4d25b4f58564042ce7fb",
      "ee0c947380534af890f4715703893d3c",
      "8c511866492046a392f7694645762617",
      "f5278f448a8441f4b2fe286583ee166a",
      "d2e926340ed9450194ab566c86401445",
      "010d2977ca9d4dd4ab3391455ba0d066",
      "2afda80a78084b09ad1f1a50f6bd2295",
      "07cda9ce394e449ea36bc93cfd16dabc"
     ]
    },
    "id": "qgLpaPHKjAwy",
    "outputId": "bfdbfe95-1a1e-4fd8-d47c-8c05e10217c7"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import Swin2SRForImageSuperResolution, Swin2SRImageProcessor\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_id = \"caidas/swin2SR-lightweight-x2-64\"\n",
    "\n",
    "processor = Swin2SRImageProcessor.from_pretrained(model_id)\n",
    "model = Swin2SRForImageSuperResolution.from_pretrained(model_id).to(device)\n",
    "model.eval()\n",
    "print(\"✅ Swin2SR-Light model loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4a-n0fIfjAwz"
   },
   "source": [
    "# Step 3: Upload Video File\n",
    "Upload the video you want to enhance (e.g., a CCTV clip)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "id": "ODmGwfD8jAwz",
    "outputId": "8b1212b9-89a8-40f4-c23a-8f6c05a42489"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()\n",
    "video_path = list(uploaded.keys())[0]\n",
    "print(\"Uploaded:\", video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFX_qFIOjAw0"
   },
   "source": [
    "# Step 4: Extract Frames from Video\n",
    "We split the video into individual frames to process them one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LrIdvjcpjAw0",
    "outputId": "814fb2c5-f8e6-487b-9cf0-6dfa41f2ed63"
   },
   "outputs": [],
   "source": [
    "import cv2, os\n",
    "os.makedirs(\"frames\", exist_ok=True)\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "i = 0\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    cv2.imwrite(f\"frames/{i:05d}.png\", frame)\n",
    "    i += 1\n",
    "cap.release()\n",
    "print(f\"✅ Extracted {i} frames at {fps:.2f} FPS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1mnAFUyujAw0"
   },
   "source": [
    "# Step 5: Define Enhancement Logic (Tiled Processing)\n",
    "To avoid memory errors on large images/frames, we use a tiled approach to enhance segments of the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Q0ylW78jAw1"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "TILE = 256\n",
    "OVERLAP = 32\n",
    "SCALE = 2\n",
    "\n",
    "def enhance_tiled(pil_img):\n",
    "    w, h = pil_img.size\n",
    "    out = Image.new(\"RGB\", (w * SCALE, h * SCALE))\n",
    "    for y in range(0, h, TILE - OVERLAP):\n",
    "        for x in range(0, w, TILE - OVERLAP):\n",
    "            tile = pil_img.crop((x, y, min(x+TILE, w), min(y+TILE, h)))\n",
    "            with torch.no_grad():\n",
    "                inputs = processor(tile, return_tensors=\"pt\").to(device)\n",
    "                outputs = model(**inputs)\n",
    "                tile_out = outputs.reconstruction[0].clamp(0, 1).cpu()\n",
    "                tile_out = (tile_out.permute(1, 2, 0).numpy() * 255).astype(\"uint8\")\n",
    "                tile_out = Image.fromarray(tile_out)\n",
    "            out.paste(tile_out, (x * SCALE, y * SCALE))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HUpdN_IzjAw1"
   },
   "source": [
    "# Step 6: Process All Frames\n",
    "This step enhances every frame using the Swin2SR model. This may take several minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mjz2juUajAw1",
    "outputId": "d059aeab-ae38-47e2-d054-80327d06212f"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "os.makedirs(\"enhanced\", exist_ok=True)\n",
    "for f in tqdm(sorted(os.listdir(\"frames\"))):\n",
    "    img = Image.open(f\"frames/{f}\").convert(\"RGB\")\n",
    "    out = enhance_tiled(img)\n",
    "    out.save(f\"enhanced/{f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abtu4umvjAw2"
   },
   "source": [
    "# Step 7: Reconstruct Enhanced Video\n",
    "We compile the processed frames back into a high-resolution video file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gWGvg7hajAw2",
    "outputId": "6fcfb8fd-b9a7-4a4b-f162-d3546c0cc1e0"
   },
   "outputs": [],
   "source": [
    "first = cv2.imread(\"enhanced/00000.png\")\n",
    "h, w, _ = first.shape\n",
    "out_video = cv2.VideoWriter(\"enhanced_video.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), fps, (w, h))\n",
    "for f in sorted(os.listdir(\"enhanced\")):\n",
    "    frame = cv2.imread(f\"enhanced/{f}\")\n",
    "    out_video.write(frame)\n",
    "out_video.release()\n",
    "print(\"✅ Enhanced video saved as enhanced_video.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhwNS0MhjAw2"
   },
   "source": [
    "# Step 8: Side-by-Side Comparison\n",
    "Compare the original video and the enhanced output side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "pPrKiCCrjAw2",
    "outputId": "6ec470f2-6178-43d7-b09d-23b9acf56f6f"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "\n",
    "def get_video_html(path, width=400):\n",
    "    # 1. Convert video to H.264 so browsers can play it\n",
    "    processed_path = path.replace(\".mp4\", \"_encoded.mp4\")\n",
    "    os.system(f\"ffmpeg -i {path} -vcodec libx264 -y {processed_path} -loglevel quiet\")\n",
    "\n",
    "    # 2. Read and Base64 encode the video\n",
    "    video_file = open(processed_path, \"rb\").read()\n",
    "    video_url = f\"data:video/mp4;base64,{base64.b64encode(video_file).decode()}\"\n",
    "\n",
    "    return f\"<video width='{width}' controls><source src='{video_url}' type='video/mp4'></video>\"\n",
    "\n",
    "# Generate the side-by-side HTML\n",
    "html_code = f\"\"\"\n",
    "<div style='display: flex; justify-content: space-around; align-items: flex-start; gap: 20px;'>\n",
    "    <div style='text-align: center;'>\n",
    "        <h3 style=\"font-family: sans-serif;\">Original Video</h3>\n",
    "        {get_video_html('/content/cctv.mp4')}\n",
    "    </div>\n",
    "    <div style='text-align: center;'>\n",
    "        <h3 style=\"font-family: sans-serif;\">Swin2SR Enhanced (2x)</h3>\n",
    "        {get_video_html('/content/enhanced_video.mp4')}\n",
    "    </div>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "from IPython.display import HTML\n",
    "display(HTML(html_code))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BSspA7GPjAw2"
   },
   "source": [
    "# Step 9: Download Results\n",
    "Download the final enhanced video to your local machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HrwyjUO3jAw2"
   },
   "outputs": [],
   "source": [
    "files.download(\"enhanced_video.mp4\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
